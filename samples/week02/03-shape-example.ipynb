{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reference\n",
    "\n",
    "To run this code you will need to install [Matplotlib](https://matplotlib.org/users/installing.html) and [Numpy](https://www.scipy.org/install.html)\n",
    "\n",
    "If you like to run the example locally follow the instructions provided on [Keras website](https://keras.io/#installation)\n",
    "\n",
    "It's __strongly__ suggested to use a Python environments manager such as [Conda](https://conda.io/docs/) or some kind of [VirutalEnv](#)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/digitalideation/digcre_h2201/blob/master/samples/week02/03-shape-example.ipynb)\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A second look at a neural network\n",
    "\n",
    "Let's try to adapt the shape classification model built with the `toyNN` in js before.\n",
    "\n",
    "We first need to create a dataset _manually_ to do we will define a `draw_shape` function that will help generating some random shape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 0 = rectangle, 1 = triangle, 2 = ellipse\n",
    "# return shape\n",
    "def draw_shape(max_size, type):\n",
    "    \n",
    "    # Random size and fixed coordinate\n",
    "#     s = math.floor(random.randrange(1, max_size-4))\n",
    "#     x = math.floor(max_size/2)\n",
    "#     y = math.floor(max_size/2)\n",
    "\n",
    "    # Not so random size and random coordinate\n",
    "    s = int(random.randrange(max_size/2, max_size))\n",
    "    x = int(random.randrange(int(s/2), max_size-int(s/2)))\n",
    "    y = int(random.randrange(int(s/2), max_size-int(s/2)))\n",
    "\n",
    "    type = type%3\n",
    "    \n",
    "    if type == 0:\n",
    "        art = plt.Rectangle((x-s/2, y-s/2), s, s, color='r')\n",
    "\n",
    "    if type == 1:\n",
    "        verts = [\n",
    "            (x-s/2, y-s/2),\n",
    "            (x, y+s/2),\n",
    "            (x+s/2, y-s/2)\n",
    "        ]\n",
    "        art = plt.Polygon(verts, color='r')\n",
    "\n",
    "    if type == 2:\n",
    "        art = plt.Circle((x, y), s/2, color='r')\n",
    "    \n",
    "    return art"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also define a helper function that convert a matplotlib figure to a np array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# https://stackoverflow.com/a/7821917\n",
    "def fig2rgb_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    return np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test the function see if it works as expected"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Image and dataset size we are going to use\n",
    "image_size = 48\n",
    "dataset_size = 5000\n",
    "\n",
    "# Create plot's figure and axes\n",
    "# https://stackoverflow.com/a/638443\n",
    "fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Setting for the axes\n",
    "ax.set_xlim(0,image_size)\n",
    "ax.set_ylim(0,image_size)\n",
    "# ax.axis('off')\n",
    "\n",
    "# Draw a random shape\n",
    "art = draw_shape(image_size,random.randint(0,2))\n",
    "# Add the shape to the plot\n",
    "# https://stackoverflow.com/a/29184075\n",
    "plt.gcf().gca().add_artist(art)\n",
    "# gcf() means Get Current Figure\n",
    "# gca() means Get Current Axis\n",
    "\n",
    "# convert the figure to an array\n",
    "data = fig2rgb_array(fig)\n",
    "print(data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(48, 48, 3)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADsAAAA4CAYAAABDsYAdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHYQAAB2EBlcO4tgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADj0lEQVRoge2aT0gUcRTHP68MtGMnqSXtFBHUpVPHCDoF3cS8BRVFCRXinvZSlouk/aEQlYwKFIQ6FEhhty4KUQQRHTzo7pgVSMKWpq6vw2/NzXZynPnNGOt84MfuzPx+773v7Oy8N7/5iaqyUdi03gFESSy2XKmwZai+vl5rampsmbNCOp3uU9Xjv3eoqpXW3Nys/xtAqxbFuKEu41hsuRKLLVdiseVKLLZcicVGysJCZK7WV+z8PCQS8OJFJO7WV+ydO/DtGzQ1QQQzJusn9udPuH3bfI6NwbNnobssKVZEjopIt4gMiMheEfkoIp0icsya5/Z2yGbN9+lpSCZD/3VLilXVp6p6ErgCHAFywFYga8XrzAx0dcHc3PK+TAYGBqyYd0VdHsYxJ6IT2A4IUAn0leh3GGitq6vz/lSdSqlWVKia33K57d6tms9H+/AuIgJcB7pVdaIwdhb46zpT1SFVTdbW1no7u7kc3L9fOuVks/DokTc7PnCbg2oEDgJVInII2ANsAR4H9nj5MjhO6WPfv0NLCzQ0wObNgV2tpKRYVb0J3LTubXoa+vshn3fvk81CTw+cPm3dfbSpJ5VavgO78eMHtLWZgsMy0YmdmoInT2BxcfW+jmMKDstEJzaZNOnFC7OzcOuWKTgsEo3YL19gcHBtYxwHbtywGkY0YpuaVv+vrmRuDjo7TQFiifDFTkzAy5f+xjoOpNPWQglf7IUL7nl1NebnobfXFCIWCFfs+Di8ehXMhuOYQsQC4YptbDSXcRDyeejrMwVJQMITOzoKw8N2bDmOKUgCEp7Yc+dgctKOrcVFU5BMTQUyE47YDx/gzRu7NjMZU5gEIByx58/D58/27Q4Owtevvod7WmYgIgngWmGzTVXfuXb+9AlGRqC62ndQruRy0NEBV6/6Gu51TcUJIAVMYh7qz7r2rK6G9+99BeOJbdt8D/UqdgeQUdUFEaksPiAihzFTM2/T6fRz35H8SQ0wZsHOzuINr2IdICEik8Bs8QFVHQKGRARVDXYHKSAirbZsFeNV7D2gBTMH1eHSZ8hKRPZt/UY0XrtYngQWKyIJEXlYaPsC2An/LYT+Y9Wal4ZJSbuAKuCuBXv7gYvAa+ABcCCozX9Okq+RpbQ0g3lr4BsR2QScAfqBA8Ap4FLgCAvYELuUlipZkZbWwlreQvjFxqpUL2nJC+G9hSgQp55yJRZbrmwosb8AHxA4ctjgOroAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 48x48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create a loop that will generate a small dataset for us"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def generate_dataset(image_size, dataset_size):\n",
    "\n",
    "    # Those variable will contain the images and associated labels\n",
    "    images = np.zeros((dataset_size, image_size, image_size, 3))\n",
    "    labels = np.zeros((dataset_size))\n",
    "    \n",
    "    # The plot figure we will use to generate the shapes\n",
    "    fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        \n",
    "        # Clear the figure\n",
    "        fig.clf()\n",
    "        \n",
    "        # Recreate the axes\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_xlim(0, image_size)\n",
    "        ax.set_ylim(0, image_size)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Define label\n",
    "        label = i%3\n",
    "        art = draw_shape(image_size, label)\n",
    "        plt.gcf().gca().add_artist(art)\n",
    "        \n",
    "        # Add values to the arrays\n",
    "        images[i] = fig2rgb_array(fig)\n",
    "        labels[i] = label\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# Generate our dataset\n",
    "images, labels = generate_dataset(image_size, dataset_size)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5000, 48, 48, 3)\n",
      "(5000,)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAC4AAAAtCAYAAADRLVmZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHYQAAB2EBlcO4tgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABy0lEQVRoge3Yv2oVQRiG8d8nCZEgKBIx5ERUCAqaIpBC7KxSptQunVZaqI3XEFAix/vwCiwEC0FETCFISi/DP2OxCQlKdHdmdkXYB6Y5e7553/MUw5yNlJL/kRP/ukAuY/GhGYsPzVh8aMbiQzMWH5qx+ND0UzzioYj1XvY+iKh+rY1YwC6+SOlG3c0P6cP4NhaxIuJWD/ujtvGIRbzD8v4nH7Cuh38rtY0/dVgaLmGjcgZqGo9YxltMfnmyi7Xa1msa3/F7abiIzYo5qGU84jLeYOmYb3zCak3rtYw/d3xpuIDblbJQw3jEFbzWHIF/4jOuSelHWWBDDeNTfy9Nc9psVchDqfGI63iF8y0n9jTWv+WHNpQan2pfmubUuVuYiZLiEWtY7Tg1j8ciZrNz9ykx/gLnMuYmuF+Qi9ziETdxNTPzJB6ImMucR77xHSwU5C7hUcF8RvHmqrpSEoo53BMxn7tBt+IRgWc4mxt4hAme5A53Nb6huarWYBZbIk5lTaeU2i0i8TGRKq6vie3WHY6sLsY3NVfUmszgjogznSc72N6rbPtgfU9Muxqfafn7Ai9xurOZdrzvOlD/9cRAjG+yhmYsPjRj8aH5CaqOJefXoyKwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 48x48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eventually we can save our dataset for later, since it takes quite some time to generate it ðŸ˜‰"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "np.save('datasets/shape-example-shapes1.npy', images)\n",
    "np.save('datasets/shape-example-labels1.npy', labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we need to load it we can then use the following code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "images = np.load('datasets/shape-example-shapes1.npy')\n",
    "labels = np.load('datasets/shape-example-labels1.npy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split our dataset manually in training and testing set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Define the size of the training set, here we use 80% of the total samples for training\n",
    "train_size = int(dataset_size*.8)\n",
    "\n",
    "# TODO: We should shuffle the dataset\n",
    "\n",
    "# Split the dataset into train and test dataset\n",
    "train_images, test_images = images[:train_size], images[train_size:]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]\n",
    "\n",
    "# Verify the data\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# sample_images = []\n",
    "# for label, image in list(zip(train_labels, train_images))[:10]:\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.axis('off')\n",
    "#     plt.title(label)\n",
    "#     fig1.add_subplot(111).imshow(image/255)\n",
    "\n",
    "full_image = np.concatenate(train_images[:12]/255, axis=1)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(full_image)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4000, 48, 48, 3)\n",
      "(4000,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1377f2090>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can create our model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"sigmoid\"),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And compile it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the `[0, 1]` interval. Then we also need to categorically encode the labels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Reshape data\n",
    "train_images = train_images.reshape((len(train_images), 3 * image_size * image_size))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((len(test_images), 3 * image_size * image_size))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Encode to categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can start the training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(train_images, train_labels, epochs=100, batch_size=128)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000/1000 [==============================] - 0s 173us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print('test_acc:', test_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_acc: 0.9850000143051147\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for label, image in list(zip(test_labels, test_images)):\n",
    "    prediction = model.predict(np.array([image,]))\n",
    "    if not prediction.argmax() == label.argmax():\n",
    "        image = image.reshape(48, 48, 3)\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.axis('off')\n",
    "        plt.title('predicted:' + str(prediction.argmax()))\n",
    "        fig1.add_subplot(111).imshow(image)    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}